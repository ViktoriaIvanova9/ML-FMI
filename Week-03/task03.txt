1. What is the problem with always using R^2? - 

R^2 не дава винаги точна преценка дали моделът е добър. Добър модел може да има ниска стойност зя R^2 и обратно.
пример: Проучвания за човешкото поведение имат R^2 < 50%, но са добри, просто човешкото поведение има допълнителни, 
по-сложни характеристики и добавяйки ги, R^2 може само да намалява или да си стои със същата стойност.

# За y = ax + b това определение ми дава най-ясна преценка какво е формално R^2 , надявам се да е вярно:
R на квадрат ни казва какъв процент от грешката на прогнозиране в променливата 
y е елиминирана, когато използваме регресия по метода на най-малките квадрати при променливата x.

2. How does using R^2(adj) help solve this problem? - 

R^2adj взима под внимание множествената линейна регресия. При добавяне на нови лейбъли/предиктори, броят им се взема под
внимание като реципрочна стойност и така можем да прец-еним спрямо добавянето на кой лейбъл, подобряваме R^2adj

3. How could we calculate R^2(adj) in Python? - 

R2adj = 1 - [(1 - R2value) * (len(y) - 1) / (len(y) - X.shape[1] - 1)]

# R2value = стойността на R^2
# len(y) - 1 = брой измервания
# X.shape[1] = брой предиктори в модела на линейната регресия 

Източници: 
https://www.statology.org/
https://statisticsbyjim.com/regression/
https://www.youtube.com/